{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning SegFormer on custom dataset\n",
    "\n",
    "This notebook follows along the blogpost from <https://huggingface.co/blog/fine-tune-segformer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hf_dataset_identifier = \"v-xchen-v/celebamask_hq\"\n",
    "ds = load_dataset(hf_dataset_identifier)\n",
    "ds[\"train\"] = ds[\"train\"].rename_column(\"image\", \"pixel_values\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store dataset locally\n",
    "# import os\n",
    "# import io\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "\n",
    "# # ds[\"train\"].to_parquet(os.environ[\"HOME\"] + \"/Data/FacialAttributes/celebamask_hq/celebamaskhq.parquet\")\n",
    "# df = pd.read_parquet(os.environ[\"HOME\"] + \"/Data/FacialAttributes/celebamask_hq/celebamaskhq.parquet\")\n",
    "# image = Image.open(io.BytesIO(df.loc[0][\"image\"][\"bytes\"]))\n",
    "# label = Image.open(io.BytesIO(df.loc[0][\"label\"][\"bytes\"]))\n",
    "# print(image)\n",
    "# print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset and split in train and test set\n",
    "\n",
    "ds = ds.shuffle(seed=1)\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2)\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "repo_id = f\"datasets/{hf_dataset_identifier}\"\n",
    "filename = \"id2label.json\"\n",
    "id2label = json.load(\n",
    "    open(\n",
    "        hf_hub_download(repo_id=hf_dataset_identifier, filename=filename, repo_type=\"dataset\"), \"r\"\n",
    "    )\n",
    ")\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "num_labels = len(id2label)\n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ColorJitter\n",
    "from transformers import SegformerImageProcessor\n",
    "\n",
    "processor = SegformerImageProcessor()\n",
    "jitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1)\n",
    "\n",
    "\n",
    "def train_transforms(example_batch):\n",
    "    images = [jitter(x) for x in example_batch[\"pixel_values\"]]\n",
    "    labels = [x for x in example_batch[\"label\"]]\n",
    "    inputs = processor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    images = [x for x in example_batch[\"pixel_values\"]]\n",
    "    labels = [x for x in example_batch[\"label\"]]\n",
    "    inputs = processor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Set transforms\n",
    "train_ds.set_transform(train_transforms)\n",
    "test_ds.set_transform(val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "pretrained_model_name = \"nvidia/mit-b0\"\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    pretrained_model_name, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "epochs = 50\n",
    "lr = 0.00006\n",
    "batch_size = 2\n",
    "\n",
    "hub_model_id = \"segformer-b0-finetuned-segments-sidewalk-2\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"../logs\",\n",
    "    learning_rate=lr,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    save_total_limit=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    eval_steps=20,\n",
    "    logging_steps=1,\n",
    "    eval_accumulation_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    # hub_model_id=hub_model_id,\n",
    "    # hub_strategy=\"end\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    with torch.no_grad():\n",
    "        logits, labels = eval_pred\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        # scale the logits to the size of the label\n",
    "        logits_tensor = nn.functional.interpolate(\n",
    "            logits_tensor,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        metrics = metric.compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=len(id2label),\n",
    "            ignore_index=0,\n",
    "            reduce_labels=processor.do_reduce_labels,\n",
    "        )\n",
    "\n",
    "        # add per category metrics as individual key-value pairs\n",
    "        per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "        metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
