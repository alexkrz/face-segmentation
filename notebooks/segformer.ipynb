{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from matplotlib.patches import Patch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils import LABEL_COLORS_DINU, label2rgb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience expression for automatically determining device\n",
    "if torch.cuda.is_available():  # Device for NVIDIA or AMD GPUs\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():  # Device for Apple Silicon (Metal Performance Shaders)\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "image_processor = SegformerImageProcessor.from_pretrained(\"jonathandinu/face-parsing\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"jonathandinu/face-parsing\")\n",
    "model.to(device)\n",
    "\n",
    "# expects a PIL.Image or torch.Tensor\n",
    "# url = \"https://images.unsplash.com/photo-1539571696357-5a69c17a67c6\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image = Image.open(\"../data/025_08.jpg\")\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on image\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits  # shape (batch_size, num_labels, ~height/4, ~width/4)\n",
    "\n",
    "# resize output to match input image dimensions\n",
    "upsampled_logits = nn.functional.interpolate(\n",
    "    logits,\n",
    "    size=image.size[::-1],\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=False,  # H x W\n",
    ")\n",
    "\n",
    "# get label masks\n",
    "labels = upsampled_logits.argmax(dim=1)[0]\n",
    "\n",
    "# move to CPU to visualize in matplotlib\n",
    "labels_viz = labels.cpu().numpy()\n",
    "print(labels_viz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a legend\n",
    "legend_patches = [\n",
    "    Patch(color=np.array(rgb), label=label)  # Normalize RGB to [0, 1] for matplotlib\n",
    "    for rgb, label in zip(list(LABEL_COLORS_DINU.values()), list(LABEL_COLORS_DINU.keys()))\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs: list[plt.Axes]\n",
    "\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Image\")\n",
    "axs[1].imshow(label2rgb(labels_viz, author=\"dinu\"))\n",
    "axs[1].set_title(\"Pred Mask\")\n",
    "axs[1].legend(handles=legend_patches, bbox_to_anchor=(1.05, 1.05), loc=\"upper left\", title=\"Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
